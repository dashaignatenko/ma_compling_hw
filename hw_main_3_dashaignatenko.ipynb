{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Доп. ранжирование по вероятности (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be25c",
   "metadata": {},
   "source": [
    "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8184734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "punctuation += \"«»—…“”\"\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import textdistance\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab492c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('data/correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c10d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('data/wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1,3))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e8632a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функции из семинара\n",
    "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
    "    # Counter можно использовать и с не целыми числами\n",
    "    similarities = Counter()\n",
    "    \n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(topn)\n",
    "\n",
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    \n",
    "    # вся эффективноть берется из того, что мы сразу считаем близость \n",
    "    # 1 вектора ко всей матрице (словам в словаре)\n",
    "    # считать по отдельности циклом было бы дольше\n",
    "    # вместо одного вектора может даже целая матрица\n",
    "    # тогда считаться в итоге будет ещё быстрее\n",
    "    \n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    \n",
    "    return [(id2word[top], similarities[top]) for top in topn]\n",
    "\n",
    "def get_closest_hybrid_match_old(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "   \n",
    "    return closest\n",
    "\n",
    "N = sum(vocab.values())\n",
    "\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N\n",
    "\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57456b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd586f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#дополненная функция\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    dist = closest[0][1]\n",
    "    closest_res = Counter() #словарь с кандидатами с одинаковым расстоянием редактирования (лучшим)\n",
    "    closest_res[closest[0]] = P(closest[0][0])\n",
    "    i = 1\n",
    "    while i < len(closest) and closest[i][1] == dist:\n",
    "        closest_res[closest[i]] = P(closest[i][0]) #каждому кандидату присваиваем вероятность\n",
    "        i += 1\n",
    "        \n",
    "    return closest_res.most_common(1)[0]\n",
    "    #return closest_res.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc08ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = get_closest_hybrid_match('вобще', X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11502fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('вообще', 0.8333333333333334), 4.228675111473113e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b8bf8",
   "metadata": {},
   "source": [
    "проверим качество\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ffc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e85f0c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff2e1e9248c418787da60c22b30bff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1], get_closest_hybrid_match(pair[1], X, vec)[0][0])\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c74cbc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8556278139069535\n",
      "0.48835403726708076\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca46849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#стало немного лучше \n",
    "#(по сравнению с семинаром:\n",
    "#0.8533266633316658\n",
    "#0.4704968944099379\n",
    "#0.09004249454461927)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cdb5bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сегодня', 'седня', ('средняя', 0.7142857142857143)),\n",
       " ('вообще', 'вобще', ('вообще', 0.8333333333333334)),\n",
       " ('вообще', 'ваще', ('чаще', 0.75)),\n",
       " ('естественно', 'естесственно', ('естественно', 0.9166666666666666)),\n",
       " ('хочется', 'хочеться', ('хочется', 0.875)),\n",
       " ('кстати', 'кстате', ('кстати', 0.8333333333333334)),\n",
       " ('очень', 'ооочень', ('сорочень', 0.75)),\n",
       " ('что-то', 'что-то', ('тото', 0.6666666666666667)),\n",
       " ('как-то', 'както', ('факто', 0.8)),\n",
       " ('очень', 'оооочень', ('сорочень', 0.75))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(wt[0], wt[1], get_closest_hybrid_match(wt[1],X,vec)) for wt, _ in Counter(mistakes).most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62eb767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (7 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Он основан только на одной операции - удалении символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов  \n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (!) \n",
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4b28f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35115a32",
   "metadata": {},
   "source": [
    "1) Составляется словарь правильных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69191ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter(re.findall('\\w+', corpus.lower(), flags=re.DOTALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c01d5",
   "metadata": {},
   "source": [
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd33e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits(word):\n",
    "    letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes_1l    = [L + R[1:]               for L, R in splits if R]\n",
    "    return set(deletes_1l)\n",
    "\n",
    "def edits2(word): \n",
    "    \"Создаем кандидатов, которые отличаются на две буквы\"\n",
    "    return (e2 for e1 in edits(word) for e2 in edits(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571e0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edited_voc(voc):\n",
    "    edits_voc = Counter()\n",
    "    for word in voc:\n",
    "        for e in edits(word):\n",
    "            if e not in edits_voc:\n",
    "                edits_voc[e] = [word]\n",
    "            else:\n",
    "                edits_voc[e].append(word)\n",
    "# с удалениями 2 букв               \n",
    "#        for e in edits2(word):\n",
    "#             if e not in edits_voc:\n",
    "#                 edits_voc[e] = [word]\n",
    "#             else:\n",
    "#                 edits_voc[e].append(word)\n",
    "    return edits_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de8341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edits_voc = make_edited_voc(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d69aa4",
   "metadata": {},
   "source": [
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления\n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59e006a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word, voc_eds, voc_all): \n",
    "    if word in voc_all.keys():\n",
    "        return word\n",
    "    #для двух удалений:\n",
    "    #eds = [w for w in edits(word) if w in voc_eds] + [w for w in edits2(word) if w in voc_eds]\n",
    "    eds = [w for w in edits(word) if w in voc_eds] #все варианты слова с удалениями\n",
    "    corrected = Counter()\n",
    "    for e in eds: #для каждого варианта удаления\n",
    "        for w in voc_eds[e]: #находим все варианты правильных слов\n",
    "            corrected[w] = P(w) #записываем \"правильные\" слова с их вероятностью\n",
    "    return corrected.most_common(1)[0][0] #выбираем самое вероятное слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1e9f8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'года'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('жода', edits_voc, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "623fbf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'конце'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('сонце', edits_voc, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c977085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b64577076d244139643d4daecca07c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "unrec = []\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        # чтобы два раза не исправлять одно и тоже слово - закешируем его\n",
    "        # перед тем как считать исправление проверим нет ли его в кеше\n",
    "        try:\n",
    "            predicted = cashed.get(pair[1], correction(pair[1], edits_voc, vocab))\n",
    "            cashed[pair[1]] = predicted\n",
    "       \n",
    "        \n",
    "\n",
    "            if predicted == pair[0]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "            if pair[0] == pair[1]:\n",
    "                total_correct += 1\n",
    "                if pair[0] !=  predicted:\n",
    "                    correct_broken += 1\n",
    "            else:\n",
    "                total_mistaken += 1\n",
    "                if pair[0] == predicted:\n",
    "                    mistaken_fixed += 1\n",
    "        except:\n",
    "            unrec.append(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d46b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8932081240445512\n",
      "0.31076178960096734\n",
      "0.04897371263953907\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вроде норм..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8f011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
