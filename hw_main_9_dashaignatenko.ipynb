{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00599409-13eb-4536-a4d3-9b1718cc94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cb19a4-fa4f-4a3f-8f0e-d3ad04d1663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58996560-2e27-4983-a5e6-ada598e75672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартные библиотеки\n",
    "import os, re\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import keras, torch\n",
    "from transformers import AutoModel, AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581cfb3",
   "metadata": {},
   "source": [
    "### Задание 1 (5 баллов).\n",
    "Это задание основано на этой тетрадке - https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/transfer_learning_hg/Fine_tunining_pretrained_LMs.ipynb\n",
    "\n",
    "Дообучите 3 предобученных модели на тех же данных, что и в семинаре. Сравните качество и выберите лучшую. \n",
    "Модели должны отличаться друг от друга не только параметрами ru/en/multilingual, base/large, cased/uncased. Все три выбранные модели должны работать лучше, чем бейзлайн без дообучения (т.е. если модель не работает, попробуйте другую).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ab0a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/lenta_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf30d5a-c9d9-4f5e-be71-fb7051114b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Из жизни             55\n",
       "Наука и техника      54\n",
       "Бывший СССР          54\n",
       "Культура             53\n",
       "Ценности             45\n",
       "Дом                  45\n",
       "Бизнес               44\n",
       "Интернет и СМИ       44\n",
       "Силовые структуры    40\n",
       "Спорт                39\n",
       "Россия               32\n",
       "Экономика            32\n",
       "Мир                  27\n",
       "69-я параллель       13\n",
       "Легпром              13\n",
       "Библиотека           10\n",
       "Крым                  7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['topic', 'text'], inplace=True)\n",
    "data.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ecec615-1f98-42fe-b392-ad2d55f08df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device_map() -> str:\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device_map() \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd66d5a8-8cc3-4348-a57e-938136ee2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilbert-base-multi-cased-finetuned-typo-detection\")\n",
    "model_mrm = AutoModelForTokenClassification.from_pretrained(\"mrm8488/distilbert-base-multi-cased-finetuned-typo-detection\", device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebdc613-d293-47a2-891c-7b2e8455c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for text in data.title:\n",
    "    ids = tokenizer.encode(text)\n",
    "    \n",
    "    X.append(ids[:512])\n",
    "\n",
    "X = keras.preprocessing.sequence.pad_sequences(X, padding='post', maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e0dab0-72e5-49e8-871b-d618c6849eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
    "label2id = {l:i for i, l in id2label.items()}\n",
    "\n",
    "y = keras.utils.to_categorical([label2id[label] for label in data.topic.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d0e3e2-2e0d-4683-bf73-e7c43f86895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, valid_index = train_test_split(list(range(len(X))), test_size=0.05, stratify=data.topic)\n",
    "\n",
    "X_train, y_train = X[train_index], y[train_index]\n",
    "X_valid, y_valid = X[valid_index], y[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706eb82d-143f-4cfd-81fa-537ffe252066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если использовать tf как бекенд то заморозить веса можно специальным параметром\n",
    "# model_bert = AutoModel.from_pretrained('distilbert-base-multilingual-cased', trainable=False)\n",
    "\n",
    "\n",
    "# в торче веса замораживаются вот так\n",
    "# если нужно заморозить не все, то нужно просто добавить условия в цикл\n",
    "for param in model_mrm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e32a1e-f11d-4f38-8ab4-e67b34e37da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с huggingface немного сложно, потому что он возвращает тип BaseModelOutput \n",
    "# который является tuple как мы посмотрели выше\n",
    "# и это немного ломает расчет размерностей в керасе потому что он пытается вытащить эту размерность \n",
    "# по атрибуту .shape а BaseModelOutput нет такого\n",
    "# этот атрибут есть у элементов этого tuple поэтому нужно написать вот такую простую обертку\n",
    "# которая вызовет модель и вернет первый элемент tuple\n",
    "class model_wrapper(keras.Model):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # модель нужно обернуть в специальный класс чтобы она была совместима с другими керас слоями\n",
    "        self.model = keras.layers.TorchModuleWrapper(model)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.model(inputs)\n",
    "        return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4256d5-c926-408e-b9db-897608875234",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_word_ids = keras.layers.Input(shape=(512,), dtype='int32', \n",
    "                                     name=\"input_ids\")\n",
    "\n",
    "\n",
    "output = model_wrapper(model_mrm)(input_word_ids)\n",
    "# добавим дропаут чтобы не переобучалось\n",
    "drop = keras.layers.Dropout(0.1)(output[:, 0]) # [0][:, 0] - означает что мы берем первое \n",
    "                                                     # состояние у всех текстов в батче\n",
    "dense = keras.layers.Dense(y.shape[1], activation='softmax')(drop)\n",
    "\n",
    "model_clf = keras.Model(inputs=[input_word_ids], outputs=dense)\n",
    "\n",
    "# обычно при дообучении трансформеров нужно ставить очень маленький лосс\n",
    "# но когда мы обучаем только итоговый классификатор то можно ставить побольше\n",
    "model_clf.compile(keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', \n",
    "                           keras.metrics.RecallAtPrecision(0.80, name='rec_prec')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b28bfd64-5a3f-49e6-add8-e978eb594e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ model_wrapper (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">model_wrapper</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │   <span style=\"color: #00af00; text-decoration-color: #00af00\">134,736,387</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ model_wrapper (\u001b[38;5;33mmodel_wrapper\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │   \u001b[38;5;34m134,736,387\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)             │            \u001b[38;5;34m68\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,736,455</span> (513.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,736,455\u001b[0m (513.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> (272.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68\u001b[0m (272.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,736,387</span> (513.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m134,736,387\u001b[0m (513.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dee8c09-5bb4-4471-b889-716b7595cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_clf.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff612632-9950-422f-a875-d2d38607cdff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# если есть ошибка с device meta то попробуйте запустить еще раз\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_clf\u001b[38;5;241m.\u001b[39mfit(torch\u001b[38;5;241m.\u001b[39mLongTensor(X_train), torch\u001b[38;5;241m.\u001b[39mLongTensor(y_train), \n\u001b[1;32m      3\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39m(torch\u001b[38;5;241m.\u001b[39mLongTensor(X_valid), torch\u001b[38;5;241m.\u001b[39mLongTensor(y_valid)),\n\u001b[1;32m      4\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/torch/core.py:163\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    161\u001b[0m device \u001b[38;5;241m=\u001b[39m get_device()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m device:\n\u001b[0;32m--> 163\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "# если есть ошибка с device meta то попробуйте запустить еще раз\n",
    "model_clf.fit(torch.LongTensor(X_train), torch.LongTensor(y_train), \n",
    "          validation_data=(torch.LongTensor(X_valid), torch.LongTensor(y_valid)),\n",
    "          batch_size=10,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "226cb27b-5484-4d83-bd1f-0f385866e875",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DistilBertTokenizerFast' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m get_device_map()  \u001b[38;5;66;03m# 'cpu'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m base_model \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      7\u001b[0m         pretrained_model_name_or_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrm8488/distilbert-base-multi-cased-finetuned-typo-detection\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# HERE\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m base_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msave_pretrained()\n\u001b[1;32m     11\u001b[0m base_model\u001b[38;5;241m.\u001b[39msave_pretrained()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DistilBertTokenizerFast' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "def get_device_map() -> str:\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device_map()  # 'cpu'\n",
    "\n",
    "base_model = AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=\"mrm8488/distilbert-base-multi-cased-finetuned-typo-detection\",\n",
    "        load_in_8bit=False,\n",
    "        device_map=device)  # HERE\n",
    "base_model.config.save_pretrained()\n",
    "base_model.save_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac881f67-cb74-4912-a26d-7e99e21dc2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f21d5e",
   "metadata": {},
   "source": [
    "### Задание 2 (5 баллов).\n",
    "\n",
    "Это задание основано на этой тетрадке - https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/gpt/gpt.ipynb\n",
    "\n",
    "Попробуйте дообучать GPT на каком-то другом тексте (можете попробовать любые стихи или какие-то специфичные вещи вроде анекдотов или репа). \n",
    "Попробуйте разные методы и параметры генерации (beam search, температура, top_k и тп). Сохраните в тетрадке несколько хороших сгенерированных текстов. \n",
    "\n",
    "Можете использовать другую модель.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444e3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
